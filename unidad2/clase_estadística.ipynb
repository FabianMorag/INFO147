{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from functools import partial\n",
    "slider_layout = widgets.Layout(width='600px', height='20px')\n",
    "slider_style = {'description_width': 'initial'}\n",
    "IntSlider_nice = partial(widgets.IntSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "FloatSlider_nice = partial(widgets.FloatSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "SelSlider_nice = partial(widgets.SelectionSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "from scipy.special import erf\n",
    "gaussian_pdf = lambda x, mu=0, s=1: np.exp(-0.5*(x-mu)**2/s**2)/(s*np.sqrt(2*np.pi))\n",
    "gaussian_cdf = lambda x, mu=0, s=1: 0.5 + 0.5*erf((x-mu)/(s*np.sqrt(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mundo de datos\n",
    "\n",
    "Los avances tecnológicos recientes nos permiten **medir, almacenar y enviar** datos de toda índole\n",
    "\n",
    "- Operaciones industriales\n",
    "- Comercio\n",
    "- Entretenimiento \n",
    "- Datos públicos y gubernamentales\n",
    "- Datos médicos\n",
    "- Ciencia: Genómica, Astronomía, Simulaciones, etc\n",
    "- Vehículos autónomos\n",
    "- Internet de las cosas\n",
    "\n",
    "> Los datos crudos tienen poco valor, necesitamos extraer información a partir de los datos\n",
    "\n",
    "- ¿Cómo se comportan mis datos? ¿Cúales son las observaciones más cómunes? ¿Qué datos son más relevantes?\n",
    "- ¿Cúal es la diferencia entre dos muestras? ¿Son las diferencias que observo reales o productos del ruido?\n",
    "- ¿Qué tan probable es que ocurra el suceso $X$? \n",
    "- ¿Qué tan arriesgado es tomar la decisión $Y$?\n",
    "\n",
    "> La **estadística** nos da herramientas para entender los procesos y tomar decisiones\n",
    "\n",
    "\n",
    "<img src=\"https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F1600%2F1*ufWDxL-5ogd22Rg_37rakw.png&f=1\">\n",
    "\n",
    "\n",
    "En esta clase aprenderemos a usar [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) y [`numpy.random`](https://docs.scipy.org/doc/numpy/reference/routines.random.html) para resolver problemas de **inferencia estadística**\n",
    "\n",
    "Pero antes, algunos fundamentos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos: Incerteza\n",
    "\n",
    "Fuentes de incerteza:\n",
    "1. Estocasticidad inherente: Sistemas con [dinámicas aleatorias](https://en.wikipedia.org/wiki/Uncertainty_principle)\n",
    "1. Observación incompleta: Sistema determinista que parece estocástico [cuando no se observa completamente](https://en.wikipedia.org/wiki/Monty_Hall_problem)\n",
    "1. Modelamiento incompleto: Los [supuestos y aproximaciones del sistema](https://en.wikipedia.org/wiki/Discretization) introducen incerteza \n",
    "\n",
    "¿Cómo representamos la incerteza?\n",
    "\n",
    "> Teoría de probabilidades\n",
    "\n",
    "Nos proporciona reglas formales para determinar la verosimilitud de una proposición versus otras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos: Variables aleatorias \n",
    "\n",
    "- **V.A.** Es una variable que, al ser observada, puede tomar diferentes valores\n",
    "\n",
    "    - La denotamos como $X$\n",
    "    \n",
    "    - Sus observaciones (realizaciones) son $x\\sim X$\n",
    "    \n",
    "    - Sus realizaciones tienen un dominio $x \\in \\mathcal{X}$\n",
    "    \n",
    "    - La probabilidad de observar $x$ es $P(X=x)$\n",
    "    \n",
    "    - Puede ser discreta o continua\n",
    "    \n",
    "\n",
    "    \n",
    "- El comportamiento de $X$ está dictado por \n",
    "    - Función de masa de probabilidad (para $X$ discreta)\n",
    "    \n",
    "    $P(X=x) \\in [0, 1]$\n",
    "    \n",
    "    $\\sum_{x\\in\\mathcal{X}} P(X=x) = 1$    \n",
    "    \n",
    "    - Función de densidad de probabilidad (para $X$ continua)\n",
    "    \n",
    "    $f(x) \\geq 0$\n",
    "    \n",
    "    $\\int_{x\\in\\mathcal{X}} f(x) \\,dx = 1$, \n",
    "    \n",
    "    $P(a\\leq X \\leq b) = F(b) - F(a) = \\int_{a}^{b} f(x) \\,dx$\n",
    "    \n",
    "        - Función de densidad acumulada: \n",
    "        \n",
    "        $F(a)  = \\int_{-\\infty}^{a} f(x) \\,dx$\n",
    "        \n",
    "        \n",
    "> **Importante:** Sólo en el caso discreto la distribución puede interpretarse como probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all'); fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "dt=1e-4; x = np.arange(-5, 5, step=dt)\n",
    "\n",
    "def update_plot(x_r):\n",
    "    xi, xf = x_r\n",
    "    for axis in ax:\n",
    "        axis.cla(); \n",
    "        axis.set_xlim([-5, 5]);\n",
    "    ax[0].plot(x, gaussian_pdf(x)); ax[1].plot(x, gaussian_cdf(x));\n",
    "    xrange = np.arange(xi, xf, step=dt)\n",
    "    ax[0].fill_between(xrange, 0, gaussian_pdf(xrange), alpha=0.5)\n",
    "    ax[1].scatter([xi, xf], [gaussian_cdf(xi), gaussian_cdf(xf)], s=100, c='k', zorder=100)\n",
    "    ax[1].text(xi+0.5, gaussian_cdf(xi), \"Init\"); ax[1].text(xf+0.5, gaussian_cdf(xf), \"End\")\n",
    "    ax[0].set_title(\"$\\int_{x_i}^{x_f} f(x) dx$ = %0.4f\" %(np.sum(gaussian_pdf(xrange))*dt))\n",
    "    area = gaussian_cdf(xf) - gaussian_cdf(xi)\n",
    "    ax[1].set_title(\"$F(x_f) - F(x_i)$ = %0.4f\" %(area if area >= 0 else 0))\n",
    "\n",
    "widgets.interact(update_plot, \n",
    "         x_r=widgets.FloatRangeSlider(description=\"$x_i, x_f$\", min=-5, max=5, value=[-1, 1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad conjunta, marginal y condicional\n",
    "\n",
    "La probabilidad de dos eventos $X=x$ e $Y=y$ se caracteriza con la distribución conjunta $P(X, Y)$\n",
    "\n",
    "A partir de la conjunta se pueden obtener la probabilidad marginal de $X$ (o de $Y$)\n",
    "\n",
    "$$\n",
    "P(X=x) = \\sum_{y \\in \\mathcal{Y}} P(X=x, Y=y) \n",
    "$$\n",
    "\n",
    "Usando la conjunta y las marginales podemos obtener las probabilidades condicionales\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "(ssi $P(X=x) \\neq 0$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "x = np.arange(-4, 5, 1)\n",
    "y = np.arange(-4, 5, 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros_like(X)\n",
    "Z[-3, 2:-2] = 1\n",
    "Z[2, 2:-2] = 1\n",
    "Z[2:-2, 4] = 1\n",
    "Z = Z/np.sum(Z)\n",
    "\n",
    "ax.bar(x, np.sum(Z, axis=1), zdir='x', zs=-4)\n",
    "ax.bar(y, np.sum(Z, axis=0), zdir='y', zs=5)\n",
    "ax.bar3d(X.ravel(), Y.ravel(), np.zeros_like(Z.ravel()), 1, 1, Z.ravel())\n",
    "ax.set_xlim([-4, 5]); ax.set_xlabel('X')\n",
    "ax.set_ylim([-4, 5]); ax.set_ylabel('Y')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "def update_plot(idx):\n",
    "    ax2.cla()\n",
    "    ax2.bar(y, Z[:, idx]/np.sum(Z[:, idx]))\n",
    "    ax2.set_title(\"P(Y|X={0})\".format(x[idx]))\n",
    "    ax2.set_ylim([0, 0.55])\n",
    "    ax2.set_xlim([-4, 4])\n",
    "    \n",
    "widgets.interact(update_plot, idx=IntSlider_nice(min=0, max=len(x), value=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independencia\n",
    "\n",
    "Si dos V.A. son independientes podemos escribir\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x, y)  &= P(x)P(y|x)\\nonumber \\\\\n",
    "&= P(x)P(y) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> Saber que ocurrió $x$ no me sirve da nada para saber si ocurrió $y$\n",
    " \n",
    "\n",
    "Dos V.A. son condicionalmente independientes si\n",
    "\n",
    "$$\n",
    "P(x, y|z)  = P(x|z)P(y|z)\n",
    "$$\n",
    "\n",
    "\n",
    "## Regla de la cadena\n",
    "\n",
    "Podemos descomponer una probabilidad conjunta como\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_1, x_2, x_3) &= P(x_3|x_2, x_1) P(x_1, x_2) \\nonumber \\\\\n",
    "&= P(x_3|x_2, x_1) P(x_2|x_1) P(x_1) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## Ley de probabilidad total\n",
    "\n",
    "Si el espacio de probabilidad está particionado en $N$ pedazos y se conocen las probabilidades condicionales $P(X=x|Y=y_i)$ podemos calcular la probabilidad del evento $x$ usando\n",
    "\n",
    "$$\n",
    "P(X=x) = \\sum_{i=1}^N P(X=x|Y=y_i) P(Y=y_i)\n",
    "$$\n",
    "\n",
    "## Teorema de Bayes\n",
    "\n",
    "Podemos escribir \n",
    "\n",
    "- la probabilidad de un evento $y$ dado condiciones $x$: $p(y|x)$ \n",
    "- en función de nuestro conocimiento *a priori* sobre $y$: $p(y$)\n",
    "- y de la verosimilitud de que se observen dichas condiciones si $y$ ocurriese: $p(x|y)$\n",
    "\n",
    "como\n",
    "\n",
    "$$\n",
    "P(y | x) = \\frac{P(x|y) P(y)}{P(x)} = \\frac{P(x|y) P(y)}{\\sum_{y\\in\\mathcal{Y}} P(x|y) P(y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptores de las distribuciones\n",
    "\n",
    "Podemos describir una variable aleatoria $X$ con $x \\sim f(x)$ usando\n",
    "\n",
    "### Valor esperado\n",
    "\n",
    "El valor medio de $X$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x\\sim f(x)} [ X ] = \\int_{x\\in \\mathcal{X}} x f(x)  \\,dx\n",
    "$$\n",
    "\n",
    "### Varianza \n",
    "\n",
    "La dispersión de $X$ en torno a su valor medio\n",
    "\n",
    "$$\n",
    "\\text{Var}[X]  = \\mathbb{E}_{x\\sim f(x)} \\left[\\left(X - \\mathbb{E}[X] \\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "la relación lineal entre $X$ e $Y$\n",
    "\n",
    "$$\n",
    "\\text{Cov}[X, Y]  = \\mathbb{E}_{x\\sim f_X(x), y\\sim f_Y(y)} \\left[\\left(X - \\mathbb{E}[X] \\right) \\left(Y - \\mathbb{E}[Y] \\right)^T \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "### Momentos estadísticos\n",
    "\n",
    "$$\n",
    "m_k [X] = \\mathbb{E}_{x\\sim f(x)} [ X^k ]\n",
    "$$\n",
    "\n",
    "- Tercer momento: Simetría \n",
    "- Cuarto momento: Cúrtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(7, 3), tight_layout=True)\n",
    "x = np.linspace(-4, 4, num=1000)\n",
    "\n",
    "def update_plot(loc, scale, skew, shape):\n",
    "    distribution1 = scipy.stats.skewnorm(skew, loc=loc, scale=scale)\n",
    "    distribution2 = scipy.stats.gennorm(shape, loc=loc, scale=scale*np.sqrt(2))\n",
    "    [ax_.cla() for ax_ in ax]\n",
    "    ax[0].plot(x, distribution1.pdf(x))\n",
    "    ax[1].plot(x, distribution2.pdf(x))\n",
    "    \n",
    "widgets.interact(update_plot, loc=FloatSlider_nice(min=-3, max=3), \n",
    "                 scale=FloatSlider_nice(min=0.01, max=2., value=1), \n",
    "                 skew=FloatSlider_nice(min=-5, max=5, value=0),\n",
    "                 shape=FloatSlider_nice(min=0.1, max=10, value=2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas distribuciones de probabilidad\n",
    "\n",
    "| Distribución | Fenomeno que representa | Ejemplo |\n",
    "| --- | --- | --- |\n",
    "| **Bernoulli** | Evento binario  | Lanzamiento de una moneda |\n",
    "| **Binomial** | Multiples eventos binarios independientes | |\n",
    "| **Categórica** | Evento con $k$ valores posibles | Lanzamiento de un dado, Ruleta |\n",
    "| **Poisson** | Conteo de eventos ocurridos en un período de tiempo | Cantidad de alumnos que llegan entre 9:50 y 10:00| \n",
    "| **Exponencial** | Valor continuo positivo | Tiempo de espera entre eventos|\n",
    "| **Gamma** | Valor continuo positivo | Tiempos de espera hasta que ocurren $n$ eventos|\n",
    "| **Beta** | Valor continuo en $[0, 1]$ |  Tiempo para completar una tarea, proporciones|\n",
    "| **Normal/Gaussiana** | Valor continuo ubicado en la vecindad de un valor central| [Demasiados](https://galtonboard.com/probabilityexamplesinlife)|\n",
    "| **Uniforme** | Valor discreto/continuo acotado a un rango, todos con igual probabilidad de ocurrencia| |\n",
    "\n",
    "<img src=\"https://thumbs.gfycat.com/AggressiveAromaticBuckeyebutterfly-size_restricted.gif\">\n",
    "\n",
    "***\n",
    "\n",
    "Podemos usar `np.random` para generar números aleatorios con distintas propiedades\n",
    "- `randn` : Números reales con distribución normal estándar\n",
    "- `rand`: Números reales con distribución uniforme en $[0, 1]$\n",
    "- `randint(low=1, high=10)`: Números enteros con distribución uniforme entre $[0, 10]$\n",
    "\n",
    "Podemos usar `scipy.stats` para generar datos de una distribución específica\n",
    "- [continua](https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions)\n",
    "- [multivariada](https://docs.scipy.org/doc/scipy/reference/stats.html#multivariate-distributions)\n",
    "- [discreta](https://docs.scipy.org/doc/scipy/reference/stats.html#discrete-distributions)\n",
    "\n",
    "Las distribuciones tienen un constructor específico y métodos\n",
    "- `pdf`/`pmf(x)` Retorna la distribución de probabilidad evaluada en $x$\n",
    "- `cdf(x)` Distribución acumulada evaluada en $x$\n",
    "- `ppf(p)` Inverso de la distribución acumulada\n",
    "- `rvs(size=100)` Retorna $100$ muestras a partir de la distribución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En detalle: Gaussiana/Normal Multivariada\n",
    "\n",
    "- Dominio $x\\in \\mathbb{R}^d$\n",
    "- Parámetros: \n",
    "    - Media $\\mathbb{E}[X] = \\mu \\in \\mathbb{R}^d$ \n",
    "    - Covarianza $\\mathbb{E}[(X-\\mu)(X-\\mu)^T] = \\Sigma \\in \\mathbb{R}^{d\\times d}$ (semidefinida positiva)\n",
    "- Función de densidad de probabilidad\n",
    "$$\n",
    "p(x| \\mu, \\Sigma) = \\frac{1}{ \\sqrt{(2 \\pi)^d} |\\Sigma |} \\exp \\left ( -\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\right)\n",
    "$$\n",
    "\n",
    "- Casos especiales\n",
    "    - Covarianza diagonal: $\\Sigma = [\\sigma_1^2, \\sigma_2^2, \\ldots, \\sigma_d^2] I$\n",
    "    - Covarianza isotrópica (esférica): $\\Sigma = \\sigma^2 I$\n",
    "    - Normal estándar: $\\mu = [0, 0, \\ldots, 0]$, $\\Sigma = I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5, 4))\n",
    "\n",
    "def update_plot(mu1, mu2, s1, s2, rho, seed):\n",
    "    ax.cla()\n",
    "    np.random.seed(seed)\n",
    "    mu = np.array([mu1, mu2]); s = np.diag(np.array([s1, s2]))\n",
    "    rot_mat = [[np.cos(rho), -np.sin(rho)], [np.sin(rho), np.cos(rho)]]\n",
    "    L = np.dot(rot_mat, s)\n",
    "    #x = np.random.multivariate_normal(mean=mu, cov=np.dot(L, L.T), size=5000)\n",
    "    dist = scipy.stats.multivariate_normal(mean=mu, cov=np.dot(L, L.T))\n",
    "    x = np.linspace(-3, 3)\n",
    "    X, Y = np.meshgrid(x, x)\n",
    "    Z = dist.pdf(np.dstack((X, Y)))\n",
    "    ax.contour(X, Y, Z)\n",
    "    xhat = dist.rvs(size=5000)\n",
    "    ax.scatter(xhat[:, 0], xhat[:, 1], s=5, alpha=0.5)\n",
    "    ax.set_xlim([-3, 3]); ax.set_ylim([-3, 3])\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "widgets.interact(update_plot, mu1=FloatSlider_nice(min=-2, max=2), mu2=FloatSlider_nice(min=-2, max=2),\n",
    "                 s1=FloatSlider_nice(value=1, min=0.1, max=2), s2=FloatSlider_nice(value=1, min=0.1, max=2),\n",
    "                 rho=FloatSlider_nice(value=0, min=-np.pi/2, max=np.pi/2), seed=IntSlider_nice());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ley de los grandes números\n",
    "\n",
    "Si $X_1, X_2, \\ldots, X_N$ son V.A independientes e idénticamente distribuidas (iid) con media $\\mu$  entonces su promedio\n",
    "\n",
    "$$\n",
    "\\bar X = \\frac{1}{N} (X_1 + X_2 + \\ldots + X_N)\n",
    "$$\n",
    "\n",
    "tiende a $\\bar X \\to \\mu$ cuando $N \\to \\infty$\n",
    "\n",
    "## Teorema central del límite\n",
    "\n",
    "Si $X_1, X_2, \\ldots, X_N$ son V.A iid, entonces su promedio \n",
    "\n",
    "$$\n",
    "\\bar X \\sim \\mathcal{N}(\\mu, \\sigma^2/N)\n",
    "$$\n",
    "\n",
    "> Sin importar su distribución original, si sumo muchas VA iid entonces la suma se distribuye normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En detalle: Distribución multinomial\n",
    "\n",
    "- Dominio $x \\in \\{0, 1, \\ldots n\\}^k$\n",
    "- Parámetros: \n",
    "    - $n>0$: Número de experimentos \n",
    "    - ${p_1, p_2, \\ldots, p_k}$: Probabilidad de las categorías donde $\\sum_i p_i = 1$\n",
    "- Función de masa de probabilidad\n",
    "$$\n",
    "p(x| m, \\{p\\}) = \\frac{n!}{x_1! x_2! \\cdots x_k!} \\prod_{i=1}^k {p_i}^{x_i}\n",
    "$$\n",
    "\n",
    "- Casos especiales\n",
    "    - $k = 2$: Distribución binomial\n",
    "    - $k = 2$ y $n = 1$: Distribución Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = scipy.stats.multinomial(n=2, p=[1/6]*6)\n",
    "dist.rvs(size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "def update_plot(k):\n",
    "    ax.cla()\n",
    "    ax.set_title(\"Promedio de {0} lanzamiento/s de dado\".format(k+1))\n",
    "    dist = scipy.stats.multinomial(n=k+1, p=[1/6]*6)\n",
    "    repeats = dist.rvs(size=1000)/(k+1)\n",
    "    average_dice = np.sum(repeats*range(1, 7), axis=1)\n",
    "    ax.hist(average_dice, bins=12, density=True)\n",
    "    ax.set_xlim([1, 6])\n",
    "update_plot(0)\n",
    "#anim = animation.FuncAnimation(fig, update_plot, frames=20, interval=300, \n",
    "#                               repeat=True, blit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística\n",
    "\n",
    "La estadística busca:\n",
    "\n",
    "> Describir fenómenos complejos a partir de observaciones parciales \n",
    "\n",
    "> Inferir propiedades de una población basándonos en una muestra\n",
    "\n",
    "> Usar datos para responder preguntas y tomar decisiones\n",
    "\n",
    "La estadística es:\n",
    "\n",
    "> Disciplina científica dedicada al desarrollo y estudio de métodos para recopilar, analizar y extraer información de los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadística descriptiva\n",
    "\n",
    "Sea una muestra de datos. Para entenderla mejor podemos empezar describiendola:\n",
    "- ¿Discreto o continuo? ¿No-negativo?\n",
    "- ¿Dónde está localizada? **Media**\n",
    "- ¿Cuál es su disperción? **Varianza**\n",
    "- ¿Son las colas iguales o distintas? **Simetría** (*Skewness*)\n",
    "- ¿Son las colas ligeras o pesadas? **Curtosis** (*Kurtosis*)\n",
    "- ¿Tiene una moda o múltiples modas?\n",
    "- ¿Cuantiles? ¿Percentiles? \n",
    "- ¿Existen *outliers*?\n",
    "\n",
    "Podemos responder estas preguntas usando [estadísticos de resumen](https://docs.scipy.org/doc/scipy/reference/stats.html#summary-statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-11, 10, num=1000)\n",
    "px = 0.7*gaussian_pdf(x, mu=-4, s=2) + 0.3*gaussian_pdf(x, mu=3, s=2)\n",
    "N = 1000; \n",
    "np.random.seed(0)\n",
    "hatx = np.concatenate((-4 + 2*np.random.randn(int(0.7*N)), \n",
    "                       (3 + 2*np.random.randn(int(0.3*N)))))\n",
    "\n",
    "scipy.stats.describe(hatx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ciertos casos podemos responder estas preguntas graficamente usando:\n",
    "\n",
    "### Histograma\n",
    "\n",
    "- Es una representación numérica de una distribución\n",
    "- Nos permite visualizar las características de la distribución\n",
    "- Se construye dividiendo el dominio en **bines** y contando los datos que caen en cada **bin**\n",
    "- Está definido por la posición y tamaño de los bines\n",
    "- Método no-paramétrico para representar distribuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all'); fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "def update_plot(nbins): \n",
    "    ax.cla()\n",
    "    ax.plot(x, px, 'k-', linewidth=4, alpha=0.8)\n",
    "    hist, bin_edges = np.histogram(hatx, bins=nbins, density=True)\n",
    "    ax.bar(bin_edges[:-1], hist, width=bin_edges[1:] - bin_edges[:-1], \n",
    "           edgecolor='k', align='edge', alpha=0.8)\n",
    "    ax.set_xlabel('x')\n",
    "    \n",
    "widgets.interact(update_plot, nbins=SelSlider_nice(options=[2, 5, 10, 15, 20, 50], value=5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel density estimation (KDE)\n",
    "\n",
    "Mismo objetivo que el histograma pero\n",
    "1. Cada dato es \"su propio bin\"\n",
    "1. Los bines se pueden traslapar\n",
    "1. No se escoge la posición o fronteras de bines, solo su ancho\n",
    "\n",
    "Para un set de observaciones unidimensionales $\\{x_i\\}_{i=1,\\ldots, N}$ con dominio continuo\n",
    "\n",
    "$$\n",
    "\\hat f_h(x) = \\frac{1}{Nh} \\sum_{i=1}^N \\kappa \\left ( \\frac{x - x_i}{h} \\right)\n",
    "$$\n",
    "\n",
    "donde \n",
    "- $h$ es el **ancho de banda del kernel** o **tamaño de kernel**\n",
    "- $\\kappa(u)$ es una **función de kernel** que debe ser positiva, con media cero e integrar a la unidad\n",
    "\n",
    "Por ejemplo  el famoso kernel Gaussiano\n",
    "\n",
    "$$\n",
    "\\kappa(u) = \\frac{1}{\\sqrt{2\\pi}} \\exp \\left ( - \\frac{u^2}{2} \\right),\n",
    "$$\n",
    "\n",
    "Ojo: \n",
    "- Usar un kernel gaussiano no es lo mismo que asumir que los datos se distribuyen gaussianos\n",
    "- Se puede usar un kernel gaussiano en datos que no se distribuyen gaussianos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "plt.close('all'); fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(x, px, 'k-', linewidth=4, alpha=0.8)\n",
    "ax.scatter(hatx, np.zeros_like(hatx), marker='+', c='k', s=20, alpha=0.1)\n",
    "ax.set_xlabel('x')\n",
    "line_kde = ax.plot(x, np.zeros_like(x))\n",
    "#hs = 0.9*np.std(hatx)*N**(-1/5)\n",
    "def update(k): \n",
    "    kde = scipy.stats.gaussian_kde(hatx, bw_method=lambda kde: k*kde.silverman_factor() )\n",
    "    line_kde[0].set_ydata(kde.pdf(x))\n",
    "    \n",
    "widgets.interact(update, k=SelSlider_nice(description=\"$k=h/h_s$\", options=[1/8, 1/4, 1/2, 1, 2, 4], value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más opciones de kernels en [`sklearn.neighbors.KernelDensity`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia estadística\n",
    "\n",
    "> Extraer conclusiones a partir de hechos a través de una premisa científica\n",
    "\n",
    "- Hechos: Datos\n",
    "- Premisa: Modelo probabilístico\n",
    "- Conclusión: Una cantidad no observada que es interesante\n",
    "\n",
    "> Cuantificar la incerteza de la conclusión dado los datos y el modelo \n",
    "\n",
    "Tareas inferenciales\n",
    "- Ajustar un modelo: **Máxima verosimilitud**\n",
    "- Verificar el modelo: **Intervalo de confianza**\n",
    "- Responder una pregunta usando el modelo: **Test de hipótesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de modelos paramétricos\n",
    "\n",
    "Se refieren a aquellos modelos que explicitan una distribución de probabilidad\n",
    "\n",
    "**Ejemplo:** Queremos ajustar un modelo lineal en sus parámetros a un conjunto de $M$ observaciones ruidosas\n",
    "\n",
    "Podemos modelar \n",
    "\n",
    "$$\n",
    "y_i = \\Phi(x_i) \\theta + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "donde $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "es decir que **asumimos** que el ruido es\n",
    "- Independiente\n",
    "- Gaussiano\n",
    "- Con media cero y varianza $\\sigma^2$\n",
    "\n",
    "Con esto podemos escribir la probabilidad de observar $y_i$ dado un cierto valor $\\theta$ como\n",
    "\n",
    "$$\n",
    "p(y_i|\\theta) = \\mathcal{N}(\\Phi(x_i) \\theta, \\sigma^2)\n",
    "$$\n",
    "\n",
    "La probabilidad de haber observado el conjunto completo es\n",
    "$$\n",
    "p(y_1, y_2, \\ldots, y_M| \\theta)\n",
    "$$\n",
    "\n",
    "Podemos **asumir** que los datos son independientes e identicamente distribuidos, en ese caso\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(y_1, y_2, \\ldots, y_M| \\theta) &= \\prod_{i=1}^M p(y_i|\\theta) \\nonumber \\\\\n",
    "&= \\prod_{i=1}^M  \\frac{1}{\\sqrt{2\\pi}\\sigma}  \\exp \\left ( - \\frac{1}{2\\sigma^2} (y_i - \\Phi(x_i) \\theta)^2 \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***\n",
    "Llamaremos **verosimilitud** de $\\theta$ a \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\prod_{i=1}^M p(y_i|\\theta) \n",
    "$$\n",
    "\n",
    "y buscamos el $\\theta$ más \"verosimil\" maximizando $\\mathcal{L}$ en función de $\\theta$\n",
    "***\n",
    "\n",
    "Por conveniencia se trabaja con el logaritmo de la verosimilitud. Para el caso anterior\n",
    "\n",
    "$$\n",
    "\\max_\\theta \\log \\mathcal{L}(\\theta) = -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^M (y_i - \\Phi(x_i) \\theta)^2\n",
    "$$\n",
    "\n",
    "Por lo tanto \n",
    "$$\n",
    "\\min_\\theta \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^M (y_i - \\Phi(x_i) \\theta)^2\n",
    "$$\n",
    "\n",
    "Que corresponde al problema de **mínimos cuadrados**\n",
    "\n",
    "¿Qué estamos asumiendo cuando usamos mínimos cuadrados?\n",
    "\n",
    "¿Qué tan confiable es $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de máxima verosimilitud\n",
    "\n",
    "El procedimiento que acabamos de ver se llama *maximum likelihood estimation* (MLE)\n",
    "\n",
    "Procedimiento\n",
    "\n",
    "1. Definir los supuestos del problema y el modelo\n",
    "1. Escribir el logaritmo de la verosimilud de los parámetros $\\log \\mathcal{L}(\\theta)$\n",
    "1. Encontrar $\\theta$ que maximiza \n",
    "$$\n",
    "\\hat \\theta = \\text{arg}\\max_\\theta \\log \\mathcal{L}(\\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "Las distribuciones de  `scipy.stats` tienen los métodos\n",
    "- `fit (data)` Ajusta una distribución continua a datos usando MLE\n",
    "- `expect (func)` Valor esperado de una función c/r a la distribución\n",
    "- `interval (alpha)` Cotas para el intervalo que contiene un porcentaje $\\alpha$ de la distribución\n",
    "\n",
    "Para distribuciones complicadas sin solución analítica se pueden usar métodos iterativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos \n",
    "\n",
    "Observemos la siguiente distribución, ¿Qué características resaltan? ¿Qué distribución sería apropiado ajustar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data_set = datasets.load_breast_cancer()\n",
    "x, y = data_set['data'][:, 0], data_set['target']\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "ax.hist(x, bins=20, density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar varias distribuciones y observar el resultado\n",
    "\n",
    "¿Cómo medir la bondad del ajuste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(np.amin(x), np.amax(x), num=50)\n",
    "dist = scipy.stats.norm\n",
    "# for dist in [scipy.stats.norm, scipy.stas.lognorm, scipy.stats.beta, scipy.stats.gamma, scipy.stats.uniform]:\n",
    "params = dist.fit(x)\n",
    "print(dist.name)\n",
    "print(params)\n",
    "p_plot = dist(*params[:-2], loc=params[-2], scale=params[-1]).pdf(x_plot)\n",
    "ax.plot(x_plot, p_plot, label=dist.name)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bondad de ajuste\n",
    "\n",
    "Podemos usar el test chi-cuadrado, el [test de Akaike](https://en.wikipedia.org/wiki/Akaike_information_criterion), el test no-paramétrico de Kolmogorov-Smirnov (KS) o gráficos QQ para medir que tan bien se ajusta nuestra distribución teórica a los datos\n",
    "\n",
    "El test KS nos permite comparar que tan distinta es una distribución continua empírica de una teórica comparando sus CDFs: [`stats.kstest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html)\n",
    "\n",
    "Require que los datos estén estandarizados (media cero y desviación estándar 1)\n",
    "\n",
    "- Retorna un estadístico: Mientras más cerca a cero, mejor es el ajuste\n",
    "- También retorna un p-value: Si es menor que $\\alpha$ entonces rechazo la hipótesis nula de que las distribuciones son iguales con un $1-\\alpha$ de confianza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = (x-np.mean(x))/np.std(x)\n",
    "ks_res = []\n",
    "for dist in [scipy.stats.norm, scipy.stats.lognorm, scipy.stats.beta, scipy.stats.gamma, scipy.stats.uniform]:    \n",
    "    params = dist.fit(x_std)\n",
    "    fitted_dist = dist(*params[:-2], loc=params[-2], scale=params[-1])\n",
    "    ks_res.append(scipy.stats.kstest(rvs=x_std, cdf=fitted_dist.cdf))\n",
    "    print(dist.name)\n",
    "    print(ks_res[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OJO: Hasta acá llegamos hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "Sea el siguiente dataset de consumo de helados per capita\n",
    "\n",
    "¿Existe correlación entre el consumo de helados y la temperatura?\n",
    "\n",
    "¿Cómo respondemos esta pregunta usando la formalidad estadística?\n",
    "\n",
    "Partamos por ajustar un modelo. Asumiendo error gaussiano, muestras iid y un modelo lineal de dos parámetros\n",
    "\n",
    "$$\n",
    "y_i = \\theta_0 + \\theta_1 x_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "El estimador de máxima verosimilitud para $\\theta$ se obtiene resolviendo\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^M (y_i - \\theta_0 - \\theta_1 x_i)^2\n",
    "$$\n",
    "\n",
    "donde \n",
    "$$\n",
    "\\sum_i y_i  - M\\theta_0 - \\theta_1  \\sum_i x_i = 0 \\rightarrow \\theta_0 = \\bar y - \\theta_1 \\bar x\n",
    "$$\n",
    "$$\n",
    "\\sum_i y_i x_i - \\theta_0 \\sum_i x_i - \\theta_1 \\sum_i x_i^2 = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_1 = \\frac{ \\sum_i (y_i - \\bar y)}{\\sum_i (x_i - \\bar x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "\n",
    "temp = np.linspace(10, 30, num=50)\n",
    "np.random.seed(0)\n",
    "helados = 0.5*temp - 2 + 1.5*np.random.randn(len(temp))\n",
    "\n",
    "ax.scatter(temp, helados)\n",
    "ax.set_xlabel('Temperatura')\n",
    "ax.set_ylabel('Consumo de helados promedio\\nmensual per capita en Chile');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bootstrap resampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.norm().fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_basis = lambda x,N : np.vstack([x**k for k in range(N)]).T\n",
    "x = np.linspace(0, 2, num=100)\n",
    "y = 2*np.cos(2.0*np.pi*x) + np.sin(4.0*np.pi*x) + 0.6*np.random.randn(len(x))\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 4), tight_layout=True, \n",
    "                       sharex=True, sharey=True)\n",
    "ax[0].scatter(x, y, c='k'); ax[1].scatter(x, y, c='k')\n",
    "\n",
    "T = 10\n",
    "N = 7\n",
    "thetas, curves = [], []\n",
    "for i in range(T):\n",
    "    idx = np.random.choice(range(len(x)), size=len(x), replace=True)\n",
    "    thetas.append(np.linalg.lstsq(poly_basis(x[idx], N), y[idx], rcond=None)[0])\n",
    "    curves.append(np.dot(poly_basis(x, N), thetas[i]))\n",
    "    ax[0].plot(x, curves[i])\n",
    "thetas, curves = np.stack(thetas), np.stack(curves)\n",
    "mu, std = np.mean(curves, axis=0), np.std(curves, axis=0)\n",
    "ax[1].plot(x, mu, lw=4);\n",
    "ax[1].fill_between(x, mu-std*3, mu+std*3, alpha=0.5);\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "ax[0].hist(thetas[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all'); fig, ax = plt.subplots(figsize=(7, 4))\n",
    "def update(N, T):\n",
    "    ax.cla(); ax.set_xlabel('x')\n",
    "    np.random.seed(0)\n",
    "    x = np.random.randn(N) # zero mean, unit variance\n",
    "    mle_mu = np.mean(x)    \n",
    "    mle_mu_bs = [np.mean(np.random.choice(x, size=len(x), replace=True)) for k in range(T)]\n",
    "    hist_val, hist_lim, _ = ax.hist(mle_mu_bs, density=True, alpha=0.6)\n",
    "    t = np.linspace(hist_lim[0], hist_lim[-1], num=200)\n",
    "    ax.plot(t, gaussian_pdf(t, mu=mle_mu, s=1/np.sqrt(len(x))), 'k-', linewidth=4)  \n",
    "    ax.scatter(np.mean(x), 0, c='k', s=100, zorder=100)\n",
    "    display(\"Empirical confidence interval at 0.95 = [%0.4f, %0.4f]\" %(np.sort(mle_mu_bs)[int(0.05*T)], \n",
    "                                                                       np.sort(mle_mu_bs)[int(0.95*T)]))    \n",
    "widgets.interact(update, N=SelSlider_nice(options=[10, 100, 1000, 10000], value=100),\n",
    "         T=SelSlider_nice(options=[10, 100, 1000, 10000], value=100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S0167715218300737"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
