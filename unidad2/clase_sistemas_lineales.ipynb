{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidad 2: Computación científica con Python\n",
    "\n",
    "\n",
    "En la **Unidad 1** estudiamos el *stack* de librerías de **Python 3** para \n",
    "- Lectura y procesamiento de datos \n",
    "- Manipulación numérica de datos\n",
    "- Visualización de datos\n",
    "\n",
    "Estos son los ingredientes para resolver problemas de matemáticas aplicadas y ciencias de la computación\n",
    "\n",
    "En las próximas clases nos enfocaremos en un problema tal vez simple pero que se encuentra en casi todas las ciencias: **resolver sistemas de ecuaciones**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de ecuaciones lineales\n",
    "\n",
    "Comenzaremos con los sistemas más simples: **Sistemas lineales en sus parámetros**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a_{11} x_{1} + a_{12} x_{2} + \\ldots + a_{1N} x_N &= b_1 \\nonumber \\\\\n",
    "a_{21} x_{1} + a_{22} x_{2} + \\ldots + a_{2N} x_N &= b_2  \\nonumber \\\\\n",
    "\\vdots  \\nonumber \\\\\n",
    "a_{M1} x_{1} + a_{M2} x_{2} + \\ldots + a_{MN} x_N &= b_M  \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Este es un sistema con $N$ incognitas y $M$ ecuaciones\n",
    "- Existen $NM + M$ parámetros que asumimos conocidos\n",
    "- Se puede escribir como un sistema matricial\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "- ¿Cómo se resuelve un sistema de este tipo?\n",
    "\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Sea el siguiente sistema\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-x_{1} + 5 x_{2} &= 2 \\nonumber \\\\\n",
    "2 x_{1} + 3 x_{2} &= 1  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "¿Cúantas ecuaciones e incognitas tiene? ¿Cúantos parámetros tiene?\n",
    "\n",
    "¿Cómo se ve geométricamente este sistema? ¿Cúal es la solución?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "x1 = np.linspace(-0.5, 0.5, num=100)\n",
    "x2_1 = (2 + x1)/5\n",
    "x2_2 = (1 - 2*x1)/3\n",
    "ax.plot(x1, x2_1, 'k-', lw=2, label='Eq. 1')\n",
    "ax.plot(x1, x2_2, 'k--', lw=2, label='Eq. 2')\n",
    "ax.grid(); ax.legend();\n",
    "ax.set_xlabel(r'$x_1$'); ax.set_ylabel(r'$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema cuadrado\n",
    "\n",
    "Este es un caso particular conocido como **sistema cuadrado** donde $N=M$\n",
    "\n",
    "Estos sistemas pueden resolverse usando\n",
    "\n",
    "$$\n",
    "x = A^{-1} b\n",
    "$$\n",
    "\n",
    "donde $A A^{-1} = I$\n",
    "\n",
    "# Algebra lineal con NumPy y SciPy\n",
    "\n",
    "Numpy nos ofrece el módulo [`linalg`](https://docs.scipy.org/doc/numpy/reference/routines.linalg.html) con funciones de algebra lineal\n",
    "\n",
    "En particular veremos la sección *Solving equations and inverting matrices*\n",
    "\n",
    "Para más funciónes podemos usar el modulo [`linalg`](https://docs.scipy.org/doc/scipy/reference/linalg.html) de SciPy\n",
    "\n",
    "#### Invirtiendo una matriz con `linalg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 5],[2,3]])\n",
    "b = np.array([2, 1])\n",
    "\n",
    "np.dot(np.linalg.inv(A), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la inversa se podía calcular como\n",
    "$$\n",
    "A = \\begin{pmatrix} a,b \\\\c,d\\end{pmatrix} \\quad A^{-1} = \\frac{1}{|A|}  \\begin{pmatrix} d,-c \\\\-b,a\\end{pmatrix} \n",
    "$$\n",
    "\n",
    "donde $|A| = ad - bc$ es el determinante de $A$\n",
    "\n",
    "En el caso general usaríamos [eliminación gaussiana](https://en.wikipedia.org/wiki/Gaussian_elimination)\n",
    "***\n",
    "El sistema tiene solución siempre y cuando $A$ sea invertible (no-singular) \n",
    "\n",
    "¿Cómo verificamos que $A\\in \\mathbb{R}^{N\\times N}$ es invertible?\n",
    "- Determinante distinto de cero\n",
    "- Rango igual a $N$  (El rango de una matriz es el número de columnas LI)\n",
    "\n",
    "Si esto no se cumple $A$ no se puede invertir \n",
    "\n",
    "#### Calculando el determinante con `linalg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Sistema sin solución\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{1} + 5 x_{2} &= 2 \\nonumber \\\\\n",
    "2 x_{1} + 10 x_{2} &= 6  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Ejemplo: Sistema con infinitas soluciones\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{1} + 5 x_{2} &= 2 \\nonumber \\\\\n",
    "2 x_{1} + 10 x_{2} &= 4  \\nonumber \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 5],[2,10]])\n",
    "b = np.array([2, 6])\n",
    "display(\"Determinante: {0}\".format(np.linalg.det(A)))\n",
    "# np.dot(np.linalg.inv(A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "x1 = np.linspace(-0.5, 0.5, num=100)\n",
    "x2_1 = (2 - x1)/5\n",
    "x2_2 = (6 - 2*x1)/10\n",
    "ax.plot(x1, x2_1, 'k-', lw=2, label='Eq. 1')\n",
    "ax.plot(x1, x2_2, 'k--', lw=2, label='Eq. 2')\n",
    "ax.grid(); ax.legend();\n",
    "ax.set_xlabel(r'$x_1$'); ax.set_ylabel(r'$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso con determinante distinto de cero podríamos no ser capaces de resolver un sistema numéricamente sin errores\n",
    "\n",
    "#### Análisis de errores\n",
    "\n",
    "Imaginemos una pequeña variación en $b$, $\\delta b$ que a su vez provoca una pequeña variación en $x$, $\\delta x$\n",
    "\n",
    "Se puede encontrar una cota que compara el error relativo de $b$ y $x$\n",
    "\n",
    "$$\n",
    "\\frac{\\| \\delta x \\|}{\\|x\\|} \\leq \\frac{\\| A^{-1} \\|  \\|\\delta b\\|}{\\|x\\|}  = \\|A^{-1}\\| \\|A\\| \\frac{\\| \\delta b \\|}{\\|b\\|} \n",
    "$$\n",
    "donde se uso que $A \\delta x = \\delta b$ (linealidad)\n",
    "\n",
    "Esto significa que un pequeño error relativo en $b$ puede causar un gran error en $x$ \n",
    "\n",
    "El estimador de $\\|A^{-1}\\| \\|A\\|$ se llama *condition number*\n",
    "\n",
    "#### Condition number\n",
    "\n",
    "Un sistema se dice \"bien condicionado\" si este valor es cercano a $1$. Si es mucho mayor a $1$ el sistema es \"mal condicionado\"\n",
    "\n",
    "A veces se retorna el recíproco del *condition number*: *RCOND*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 5],[2,3]])\n",
    "b = np.array([2, 1])\n",
    "np.linalg.cond(A, p='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(9).reshape(3, 3)\n",
    "np.linalg.cond(A, p='fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norma de una matriz con `linalg`\n",
    "\n",
    "De forma similar a los vectores se puede definir una norma para medir el \"tamaño\" de una matriz\n",
    "\n",
    "La más típica es la [norma de Frobenius](https://www.sciencedirect.com/topics/engineering/frobenius-norm)\n",
    "$$\n",
    "\\|A \\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(A, ord='fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolviendo sistemas cuadrados y  lineales eficientemente\n",
    "\n",
    "En general nos interesa $x$ más que $A^{-1}$\n",
    "\n",
    "En particular si un sistema de ecuaciones es grande es mala idea calcular la inversa (muy costoso)\n",
    "\n",
    "`linalg` tiene la función `solve` que obtiene $x$ de forma más eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "A = np.random.rand(N, N)\n",
    "b = np.random.rand(N, 1)\n",
    "%timeit -n10 np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n10 np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(np.linalg.solve(A, b), np.dot(np.linalg.inv(A), b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué `solve` es más rápido que `inv`+`dot`?\n",
    "\n",
    "`solve` realiza internamente una factorización\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A x &= b \\nonumber \\\\\n",
    "LU x &= b \\nonumber \\\\\n",
    "L z &= b \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Donde $L$ es una matriz triangular inferior (lower) y $U$ es una matriz triangular superior (upper)\n",
    "\n",
    "$$\n",
    "L = \\begin{pmatrix} \n",
    "l_{11} & 0 & 0 & \\ldots & 0 & 0 \\\\ \n",
    "l_{21} & l_{22} & 0 &\\ldots & 0 & 0 \\\\ \n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "l_{N1} & l_{N2} & l_{N3} & \\ldots & l_{N(N-1)} & l_{NN} \\\\ \n",
    "\\end{pmatrix} \\quad\n",
    "U = \\begin{pmatrix} \n",
    "u_{11} & u_{11} & u_{13} & \\ldots & u_{1(N-1)} & u_{1N} \\\\ \n",
    "u_{21} & u_{22} & u_{32} &\\ldots & u_{2(N-1)} & 0 \\\\ \n",
    "\\vdots & \\vdots & \\vdots &\\ldots & \\ddots & \\vdots \\\\\n",
    "u_{N1} & 0 & 0 & \\ldots & 0 & 0\\\\ \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Luego $z$ se puede obtener recursivamente\n",
    "\n",
    "$$\n",
    "z_1 = \\frac{b_1}{l_{11}}\n",
    "$$\n",
    "$$\n",
    "z_2 = \\frac{b_2 - l_{21} z_1}{l_{22}}\n",
    "$$\n",
    "$$\n",
    "z_i = \\frac{b_i - \\sum_{j=1}^{i-1} l_{ij} z_j}{l_{ii}}\n",
    "$$\n",
    "\n",
    "y $x$ se puede obtener recursivamente de $z$\n",
    "\n",
    "La librería `scipy` nos ofrece en su modulo `linalg` la función `lu` para factorizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "scipy.linalg.lu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 5],[2,3]])\n",
    "P, L, U = scipy.linalg.lu(A, permute_l=False)\n",
    "display(L, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need for speed\n",
    "\n",
    "NumPy y SciPy se compilan contra las librerías [BLAS](http://www.netlib.org/blas/) y [LAPACK](http://www.netlib.org/lapack/) del sistema\n",
    "\n",
    "Existen varias implementaciones de BLAS/LAPACK que son enfocadas en eficiencia\n",
    "1. [OpenBLAS](https://www.openblas.net/)\n",
    "1. Intel [MKL](https://software.intel.com/en-us/mkl)\n",
    "1. [ATLAS](http://math-atlas.sourceforge.net/)\n",
    "\n",
    "\n",
    "\n",
    "- [Comparación entre ATLAS OpenBLAS y MKL](http://blog.nguyenvq.com/blog/2014/11/10/optimized-r-and-python-standard-blas-vs-atlas-vs-openblas-vs-mkl/)\n",
    "- [Guía de instalación de MKL con conda](https://software.intel.com/en-us/articles/using-intel-distribution-for-python-with-anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__config__.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ldd /usr/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-x86_64-linux-gnu.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema rectangular\n",
    "\n",
    "Si tenemos un sistema \n",
    "\n",
    "- sobredeterminado: con más ecuaciones que incognitas\n",
    "- infradeterminado: con más incognitas que ecuaciones\n",
    "- incognitas: grados de libertad\n",
    "- ecuaciones: restricciones\n",
    "\n",
    "ya no podemos calcular la inversa\n",
    "\n",
    "Sea entonces \n",
    "$$\n",
    "A x +b \n",
    "$$\n",
    "donde $A\\in \\mathbb{R}^{M\\times N}$, $x\\in \\mathbb{R}^{N}$ y $b \\in \\mathbb{R}^{M}$\n",
    "\n",
    "### Sistema sobre determinado\n",
    "\n",
    "Asumamos $N < M$ \n",
    "\n",
    "En este caso podemos encontrar una solución aproximada minimizando la suma de errores cuadráticos\n",
    "\n",
    "$$\\\n",
    "\\min_x \\sum_{i=1}^M e_i^2 \n",
    "$$\n",
    "donde $e_i = \\sum_{j=1}^N a_{ij} x_j - b_i$\n",
    "\n",
    "Esto se conoce como el **Problema de mínimos cuadrados**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dx} \\|Ax - b \\|_F^2 &= \\frac{d}{dx}  (A x - b)^T (A x -b) \\nonumber \\\\\n",
    " &= 2 A^T (A x -b) \\nonumber \\\\\n",
    "&= 2A^T A x - 2A^T b = 0 \\nonumber \\\\\n",
    "\\rightarrow \\hat x &= (A^T A)^{-1} A^T b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $A^{\\dagger} = (A^T A)^{-1} A^T$ se conoce como la pseudo-inversa de [Moore-Penrose](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse)\n",
    "\n",
    "Que está implementada en `linalg.pinv`\n",
    "\n",
    "Y la solución de mínimos cuadrádos está implementada en [`linalg.lstsq`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad: Ajustando una recta\n",
    "\n",
    "Encuentre los parámetros de la **ecuación de la recta** que ajuste mejor los datos \n",
    "\n",
    "$$\n",
    "y = \\theta_1 x + \\theta_2\n",
    "$$\n",
    "\n",
    "- Identifique y construya el vector $b$ y la matriz $A$ ¿Cuánto vale $N$ y $M$?\n",
    "- ¿Es este un sistema cuadrado o rectangular? ¿ Es sobre o infra-determinado?\n",
    "- Encuentre $\\theta_1$ y $\\theta_2$ que minimiza la suma de errores cuadráticos\n",
    "    - Encuentre la pseudo inversa y luego use dot\n",
    "    - Use lstsq\n",
    "    - ¿Cúal método es más eficiente?\n",
    "- Grafique la recta encontrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, num=50)\n",
    "y = -4*x + 2 + 2*np.random.randn(len(x))\n",
    "fig, ax = plt.subplots(figsize=( 4, 4), tight_layout=True)\n",
    "ax.scatter(x, y); \n",
    "ax.set_xlabel('x'); ax.set_ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede hacer lo mismo con el siguiente polinomio?\n",
    "\n",
    "$$\n",
    "y = \\theta_2 x^2 + \\theta_1 x + \\theta_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 5*x + 8*x**2 + 10*np.random.randn(len(x))\n",
    "fig, ax = plt.subplots(figsize=( 4, 4), tight_layout=True)\n",
    "ax.scatter(x, y); \n",
    "ax.set_xlabel('x'); ax.set_ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "Consiste en **ajustar** un modelo paramétrico\n",
    "$$\n",
    "f_\\theta: x \\rightarrow y\n",
    "$$\n",
    "que sea capaz de predecir $y$ dado $x$\n",
    "\n",
    "- $x$ variable indepediente, entrada, característica, predictor\n",
    "- $y$ variable dependiente, salida, respuesta, objetivo (target)\n",
    "- $x$ e $y$ son variables continuas\n",
    "- $\\theta$ son los parámetros del modelo\n",
    "\n",
    "> Encontrar como dos o más variables se relacionan. Explicar una variable en función de otras. Predicción\n",
    "\n",
    "Hablamos de **regresión lineal** cuando el modelo $f_\\theta$ es **lineal en sus parámetros**\n",
    "\n",
    "¿Son estos modelos lineales en sus parámetros?\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f_\\theta(x) = \\theta_0  + \\theta_1 x  \\nonumber \\\\\n",
    "y &= f_\\theta(x) = \\theta_0  + \\theta_1 x + \\theta_2 x^2 + \\theta_3 \\log(x) \\nonumber \\\\\n",
    "y &= f_\\theta(x) = \\theta_0  + \\sin(\\theta_1) x  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "- **Datos:** conjunto de $M$ tuplas $(\\vec x_i, y_i)$ con $i=1,2,\\ldots,M$ \n",
    "- **Ajuste:** Encontrar el valor óptimo de $\\theta$ en función de los datos\n",
    "- Podemos escribir el problema como un sistema lineal de $M$ ecuaciones\n",
    "- Si el sistema es rectangular lo podemos resolver con **Mínimos Cuadrados**\n",
    "- En dicho caso la solución es óptima *\"en el sentido de mínimos cuadrádos\"*\n",
    "\n",
    "### Modelos lineales en sus parámetros y en sus entradas\n",
    "#### Recta\n",
    "Si $x$ es unidimensional \n",
    "$$\n",
    "y =\\theta_0  + \\theta_1 x \n",
    "$$\n",
    "\n",
    "#### Plano\n",
    "Si $\\vec x =(x_1, x_2)$ es bidimensional \n",
    "$$\n",
    "y = \\theta_0  + \\theta_1 x_1 +  \\theta_2 x_2 \n",
    "$$\n",
    "\n",
    "#### Hiperplano\n",
    "Si $\\vec x = (x_1, x_2, \\ldots, x_d)$ es d-dimensional\n",
    "$$\n",
    "y = \\theta_0  + \\sum_{k=1}^d \\theta_k x_k \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, SelectionSlider, IntSlider\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.close('all'); fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "theta = [4, 3, 2]; \n",
    "\n",
    "def update(rseed, N, sigma):\n",
    "    ax.cla();\n",
    "    np.random.seed(rseed);\n",
    "    x1, x2 = np.random.randn(2, N)\n",
    "    y_clean = theta[0] + theta[1]*x1 + theta[2]*x2 \n",
    "    y = y_clean + sigma*np.random.randn(len(x1))\n",
    "    X_lstsq = np.stack((np.ones_like(x1), x1, x2)).T\n",
    "    param, MSE, rank, singval = np.linalg.lstsq(X_lstsq, y, rcond=None)\n",
    "    display(theta, param)\n",
    "    ax.scatter(x1, x2, y, s=10, label='data')\n",
    "    X1, X2 = np.meshgrid(np.linspace(np.amin(x1), np.amax(x1), num=2), \n",
    "                         np.linspace(np.amin(x2), np.amax(x2), num=2))\n",
    "    ax.plot_surface(X1, X2, param[0] + param[1]*X1 + param[2]*X2, \n",
    "                    label='model', alpha=0.25)\n",
    "\n",
    "interact(update, \n",
    "         rseed=IntSlider(continuous_update=False), \n",
    "         N=SelectionSlider(options=[10, 100, 1000]),\n",
    "         sigma=SelectionSlider(options=[0.1, 0.5, 1, 2, 5, 10.]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción: Interpolación y Extrapolación\n",
    "\n",
    "Una vez que el regresor ha sido ajustado se puede usar para hacer predicciónes de la variable dependiente a partir de valores no observados de la variable independiente\n",
    "\n",
    "- Llamamos interpolación cuando predecimos dentro del rango de nuestros datos\n",
    "- Llamamos extrapolación cuando predecimos fuera del rango de nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(5)\n",
    "y = 5*x -4 + 2*np.random.randn(len(x))\n",
    "theta = np.linalg.lstsq(np.stack((np.ones_like(x), x)).T, y, rcond=None)[0]\n",
    "y_hat = lambda x : np.dot(np.stack((np.ones_like(x), x)).T, theta)\n",
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "ax.scatter(x, y, c='k')\n",
    "x_plot = np.linspace(np.amin(x), np.amax(x))\n",
    "ax.plot(x_plot, y_hat(x_plot))\n",
    "x_plot = np.linspace(np.amax(x), 2*np.amax(x))\n",
    "ax.plot(x_plot, y_hat(x_plot))\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos lineales en sus parámetros pero no en sus entradas\n",
    "\n",
    "Podemos generalizar la regresión lineal usando funciónes base $\\phi_j(\\cdot)$ tal que el modelo\n",
    "\n",
    "$$\n",
    "y = f_\\theta (x) = \\sum_{j=0}^N \\theta_j \\phi_j (x)\n",
    "$$\n",
    "\n",
    "#### Regresión lineal con polinomios\n",
    "\n",
    "Si usamos $\\phi_j(x) = x^j$ nos queda\n",
    "\n",
    "$$\n",
    "y = f_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\ldots\n",
    "$$\n",
    "\n",
    "#### Regresión lineal con sinusoides\n",
    "\n",
    "Si usamos $\\phi_j(x) = \\cos(2\\pi j x)$ nos queda\n",
    "\n",
    "$$\n",
    "y = f_\\theta (x) = \\theta_0 + \\theta_1 \\cos(2\\pi x) + \\theta_2 \\cos(4 \\pi x) + \\ldots\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2, num=100)\n",
    "y = 2*np.cos(2.0*np.pi*x) + np.sin(4.0*np.pi*x) + 0.4*np.random.randn(len(x))\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "ax.scatter(x, y)\n",
    "\n",
    "poly_basis = lambda x,N : np.vstack([x**k for k in range(N)]).T\n",
    "N = 1\n",
    "theta = np.linalg.lstsq(poly_basis(x, N), y, rcond=None)[0]\n",
    "ax.plot(x, np.dot(poly_basis(x, N), theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema infradeterminado\n",
    "\n",
    "Es aquel sistema que tiene más incognitas (parámetros) que ecuaciones, $N>M$\n",
    "\n",
    "Este tipo de sistema tiene infinitas soluciones\n",
    "\n",
    "#### Ejemplo: Dos puntos con polinomio de segundo orden (tres parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.array([-2, 2])\n",
    "y = np.array([4, 4])\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "x_plot = np.linspace(-3, 3, num=100)\n",
    "thetas = np.zeros(shape=(200, 3))\n",
    "for i, a in enumerate(np.linspace(-10, 10, num=thetas.shape[0])):\n",
    "    ax.plot(x_plot, a  + (1 - a/4)*x_plot**2)\n",
    "    thetas[i:] = [a, 0, (1-a/4)]\n",
    "ax.scatter(x, y, s=100, c='k', zorder=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso $A^T A$ no es invertible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = poly_basis(x, N=3)\n",
    "display(A)\n",
    "np.linalg.inv(np.dot(A.T, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema infradeterminado se resuelve imponiendo una restricción adicional\n",
    "\n",
    "La más típica es que el vector solución tenga norma mínima\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\| x \\|_2^2 ~\\text{s.a.}~ Ax =b\n",
    "$$\n",
    "\n",
    "que se resuelve usando $M$ multiplicadores de Lagrande\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dx} \\| x\\|_2^2 + \\lambda^T (b - Ax) &= 2x - \\lambda^T A  \\nonumber \\\\\n",
    "&= 2Ax - A A^T \\lambda \\nonumber \\\\\n",
    "&= 2b - A A^T \\lambda = 0 \\nonumber \\\\\n",
    "&\\rightarrow \\lambda = 2(AA^T)^{-1}b \\nonumber \\\\\n",
    "&\\rightarrow x = \\frac{1}{2} A^T \\lambda = A^T (A A^T)^{-1} b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $A^T (A A^T)^{-1}$ se conoce como la pseudo-inversa \"por la derecha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-2, 2])\n",
    "y = np.array([4, 4])\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "x_plot = np.linspace(-3, 3, num=100)\n",
    "theta = np.dot(np.dot(A.T, np.linalg.inv(np.dot(A, A.T))), y)\n",
    "ax.plot(x_plot, np.dot(poly_basis(x_plot, N=3), theta))\n",
    "ax.scatter(x, y, s=100, c='k', zorder=10)\n",
    "display(theta)\n",
    "display(thetas[np.argmin(np.sum(thetas**2, axis=1)), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.lstsq(A, y, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigando nos damos cuenta que `linalg.lstsq` está basado en la función de LAPACK [`dgels`](https://www.math.utah.edu/software/lapack/lapack-d/dgels.html)\n",
    "\n",
    "dgels usa la pseudo inversa izquierda si $N<M$ o la pseudo inversa derecha si $N>M$\n",
    "\n",
    "> Se asume que la mejor solución del sistema infradeterminado es la de mínima norma euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complejidad, sobreajuste y regularización\n",
    "\n",
    "Un modelo con más parámetros es más complejo pero también más flexible\n",
    "\n",
    "Un exceso de flexibilidad no es bueno\n",
    "\n",
    "El modelo se ajusta al ruido y ya no generaliza bien\n",
    "\n",
    "Se dice entonces que el modelo se ha **sobreajustado a los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, num=50)\n",
    "y = -4*x + 2 + 2*np.random.randn(len(x))\n",
    "fig, ax = plt.subplots(figsize=( 4, 4), tight_layout=True)\n",
    "ax.scatter(x, y); \n",
    "ax.set_xlabel('x'); ax.set_ylabel('y');\n",
    "\n",
    "A = poly_basis(x, N=30)\n",
    "theta = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "ax.plot(x, np.dot(A, theta), 'k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all'); fig = plt.figure(figsize=(6, 5), tight_layout=True)\n",
    "x = np.linspace(-5, 6, num=11); \n",
    "x_plot = np.linspace(-5, 6, num=100);\n",
    "theta = [10, -2, -0.3, 0.1]\n",
    "X = poly_basis(x, len(theta))\n",
    "y = np.dot(X, theta)\n",
    "\n",
    "def update(sigma, rseed, N):\n",
    "    np.random.seed(rseed); \n",
    "    Y = np.dot(X, theta) + sigma*np.random.randn(len(x))\n",
    "    X2 = poly_basis(x, N)\n",
    "    theta_hat = np.linalg.lstsq(X2[:10, :], Y[:10], rcond=None)[0]\n",
    "    print(theta, theta_hat)\n",
    "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    ax.scatter(x[:10], Y[:10], c='r', s=100, label='train data')\n",
    "    ax.scatter(x[10:], Y[10:], c='g', s=100, label='test data')\n",
    "    ax.vlines(x[:10], np.dot(X2[:10, :], theta_hat), Y[:10], 'r')  \n",
    "    ax.vlines(x[10:], np.dot(X2[10:, :], theta_hat), Y[10:], 'g') \n",
    "    ax.plot(x, y, 'b--', linewidth=4, label='underlying')\n",
    "    ax.plot(x_plot, np.dot(poly_basis(x_plot, N), theta_hat), 'k-', linewidth=4, label='model')\n",
    "    ax.set_ylim([-5, 15]); plt.legend()\n",
    "    ax = plt.subplot2grid((3, 1), (2, 0))\n",
    "    ax.plot(x, np.zeros_like(x), 'k--', alpha=0.5)\n",
    "    ax.scatter(x, Y - np.dot(X2, theta_hat), c='k', s=100); \n",
    "    \n",
    "interact(update, rseed=IntSlider(continuous_update=False), \n",
    "         N=SelectionSlider(options=[1, 2, 3, 4, 5, 7, 10]), \n",
    "         sigma=SelectionSlider(options=[0.1, 1, 2, 5]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tres maneras de evitar el sobreajuste\n",
    "\n",
    "- Usar modelos de baja complejidad \n",
    "- Escoger la complejidad usando validación cruzada\n",
    "- Usar **regularización**\n",
    "\n",
    "#### Regularización\n",
    "\n",
    "Consiste en agregar una penalización adicional al problema \n",
    "\n",
    "El ejemplo clásico es pedir que la solución tenga norma mínima\n",
    "\n",
    "$$\n",
    "\\min_x \\|Ax-b\\|_2^2 + \\lambda \\|x\\|_2^2\n",
    "$$\n",
    "\n",
    "En este caso la solución es\n",
    "\n",
    "$$\n",
    "\\hat x = (A^T A + \\lambda I)^{-1} A^T b\n",
    "$$\n",
    "\n",
    "que se conoce como **ridge regression** o **regularización de Tikhonov**\n",
    "\n",
    "$\\lambda$ es un hiper-parámetro del modelo y debe ser escogido por el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "plt.close('all'); fig, ax = plt.subplots(figsize=(7, 4))\n",
    "x = np.linspace(-5, 6, num=50); x_plot = np.linspace(-5, 6, num=200); \n",
    "model = np.sin(x)*x + 0.1*x**2\n",
    "print(repr(theta))\n",
    "\n",
    "def update(sigma, rseed, lamb, M):\n",
    "    np.random.seed(rseed); \n",
    "    y = model + sigma*np.random.randn(len(x))\n",
    "    regressor = make_pipeline(PolynomialFeatures(M), Ridge(normalize=True, alpha=lamb))\n",
    "    regressor.fit(x.reshape(-1, 1), y)\n",
    "    ax.cla(); ax.plot(x, model, 'b--', linewidth=4, label='underlying')\n",
    "    ax.plot( x_plot , regressor.predict( x_plot .reshape(-1, 1)), 'k-', linewidth=4, label='model')\n",
    "    ax.scatter(x, y, c='r', s=30, label='data', zorder=100); plt.legend()\n",
    "\n",
    "    \n",
    "interact(update, rseed=IntSlider(continuous_update=False), M=SelectionSlider(options=[1, 2, 3, 5, 10, 20]), \n",
    "         sigma=SelectionSlider(options=[0.1, 1, 2, 5]),\n",
    "         lamb=SelectionSlider(options=[0.0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1., 100000.]));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación\n",
    "\n",
    "Para escoger la cantidad de parámetros de nuestro modelo o escoger hiper-parámetros como $\\lambda$ podemos usar validación cruzada\n",
    "\n",
    "Antes de ajustar el modelo se particionan los datos en dos conjuntos\n",
    "1. Conjunto de entrenamiento: Datos que se ocupan para ajustar el modelo\n",
    "1. Conjuto de validación: Datos que se ocupan para evaluar el modelo\n",
    "\n",
    "Nos quedamos con el modelo que se desempeña mejor en validación \n",
    "\n",
    "Un modelo sobreajustado tiene buen desempeño en entrenamiento y malo en validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opciones de más alto nivel para hacer regresión lineal\n",
    "\n",
    "- `scipy.stats.linregress`\n",
    "- [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
