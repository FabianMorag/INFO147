{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from functools import partial\n",
    "import sklearn.datasets\n",
    "import scipy.linalg\n",
    "slider_layout = widgets.Layout(width='600px', height='20px')\n",
    "slider_style = {'description_width': 'initial'}\n",
    "IntSlider_nice = partial(widgets.IntSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "FloatSlider_nice = partial(widgets.FloatSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "SelSlider_nice = partial(widgets.SelectionSlider, style=slider_style, layout=slider_layout, continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices como transformaciónes lineales\n",
    "\n",
    "Sea una base de datos (tabla) con atributos continuos $V \\in \\mathbb{R}^{M\\times D}$\n",
    "- Cada ejemplo tiene $D$ atributos\n",
    "- Si asumimos que $0^D$ es el origen entonces cada ejemplo es un **vector** $D$-dimensional \n",
    "- Existen $M$ vectores $v_i \\in \\mathbb{R}^D$  en $V$ (filas)\n",
    "\n",
    "Consideremos el caso $D=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_set = sklearn.datasets.load_iris()\n",
    "V = iris_set.data[-5:, 2:]\n",
    "display(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "arrow_args = {'width': 0.05, 'length_includes_head': True, 'alpha': 0.5}\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim([0, 6]); ax.set_ylim([0, 4]); \n",
    "ax.set_xlabel(\"Largo del pétalo [cm]\")\n",
    "ax.set_ylabel(\"Ancho del pétalo [cm]\")\n",
    "\n",
    "for v in V:\n",
    "    ax.arrow(0, 0, v[0], v[1], color='k', **arrow_args)\n",
    "    ax.scatter(v[0], v[1], cmap=plt.cm.Set3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos encontrar el vector promedio (rojo) y visualizarlo geometrícamente\n",
    "- Si lo restamos podemos mover el origen de nuestros ejes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmean = np.mean(V, axis=0)\n",
    "ax.arrow(0, 0, Vmean[0], Vmean[1], color='r', **arrow_args)\n",
    "ax.scatter(Vmean[0], Vmean[1], color='k');\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "arrow_args = {'width': 0.01, 'length_includes_head': True, 'alpha': 0.5}\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim([-0.5, 0.5]); ax.set_ylim([-0.5, 0.5]); \n",
    "ax.set_xlabel(\"Largo del pétalo [cm] - %0.2f\" %(Vmean[0]))\n",
    "ax.set_ylabel(\"Ancho del pétalo [cm] - %0.2f\" %(Vmean[1]))\n",
    "\n",
    "V_ = V - Vmean \n",
    "for v in V_:\n",
    "    ax.arrow(0, 0, v[0], v[1], color='k', **arrow_args)\n",
    "    ax.scatter(v[0], v[1], cmap=plt.cm.Set3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una matriz cuadrada $A = \\begin{pmatrix} \\alpha & \\beta \\\\ \\beta & \\alpha \\end{pmatrix}$\n",
    "\n",
    "¿Qué le ocurre a nuestros datos centrados si los multiplicamos por $A$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 4), tight_layout=True)\n",
    "\n",
    "def update_plot(alpha, beta):\n",
    "    A = [[alpha, beta], [beta, alpha]]    \n",
    "    display(A)\n",
    "    ax.cla(); ax.set_aspect('equal')\n",
    "    ax.set_xlim([-0.5, 0.5]); ax.set_ylim([-0.5, 0.5]);   \n",
    "    V_ = V - Vmean \n",
    "    for v in V_:\n",
    "        ax.arrow(0, 0, v[0], v[1], color='k', **arrow_args)\n",
    "        ax.scatter(v[0], v[1], cmap=plt.cm.Set3);\n",
    "    ax.set_prop_cycle(None)    \n",
    "    Vn = np.dot(V_, A)\n",
    "    for v in Vn:\n",
    "        ax.arrow(0, 0, v[0], v[1], color='b', **arrow_args)\n",
    "        ax.scatter(v[0], v[1], cmap=plt.cm.Set3);    \n",
    "    \n",
    "widgets.interact(update_plot, \n",
    "                 alpha=FloatSlider_nice(min=-2, max=2, value=1.), \n",
    "                 beta=FloatSlider_nice(min=-2, max=2, value=0.));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación afín\n",
    "\n",
    "- Sumando un vector podemos trasladar nuestros datos\n",
    "- Multiplicando por una matriz cuadrada podemos rotar y escalar nuestros datos\n",
    "- La combinación de estas operaciones se conoce como [**transformación afín**](https://en.wikipedia.org/wiki/Affine_transformation#Image_transformation)\n",
    "\n",
    "$$\n",
    "v = A v' + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bases y transformaciones\n",
    "\n",
    "La base de un espacio es un conjunto de vectores tal que todos los elementos del espacio se pueden escribir como una combinación de esos vectores\n",
    "\n",
    "En el caso bidimensional la base trivial es $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "y un vector cualquiera puede representarse como\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x \\\\ y \\end{pmatrix} = x \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + y \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Geometricamente podemos interpretar la base como los **ejes coordenados** de nuestro sistema\n",
    "\n",
    "### Cambio de coordenadas\n",
    "\n",
    "Una multiplicación por una matriz podría verse entonces como un \"cambio de ejes coordenados\"\n",
    "\n",
    "¿Qué le ocurre a la base trivial si la multiplicamos por $A = \\begin{pmatrix} a_1 & a_2 \\\\ a_3 & a_4 \\end{pmatrix}$\n",
    "\n",
    "¿Cómo se ven los datos en el nuevo espacio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6, 4), tight_layout=True)\n",
    "world_axis = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "def update_plot(a1, a2, a3, a4):\n",
    "    A = [[a1, a2], [a3, a4]]\n",
    "    new_world_axis = np.dot(A, world_axis)\n",
    "    print(new_world_axis)\n",
    "    for ax_ in ax:\n",
    "        ax_.cla(); ax_.set_aspect('equal')\n",
    "        ax_.set_xlim([-1, 1]); ax_.set_ylim([-1, 1]);  \n",
    "        ax_.spines['right'].set_color('none')\n",
    "        ax_.spines['top'].set_color('none')\n",
    "        ax_.spines['bottom'].set_position(('data', 0))\n",
    "        ax_.spines['left'].set_position(('data', 0))        \n",
    "        ax_.xaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "        ax_.yaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "    ax[1].spines['bottom'].set_color('blue') \n",
    "    ax[1].spines['left'].set_color('green') \n",
    "    ax[0].set_title('Espacio original')\n",
    "    ax[1].set_title('Proyección en los nuevos ejes')\n",
    "    for j, c in enumerate(['b', 'g']):\n",
    "        ax[0].arrow(0, 0, new_world_axis[0, j], new_world_axis[1, j], color=c, **arrow_args)\n",
    "    V_ = V - Vmean \n",
    "    for v in V_:\n",
    "        ax[0].scatter(v[0], v[1], cmap=plt.cm.Set3);\n",
    "    Vn = scipy.linalg.solve(A, V_.T).T\n",
    "    for v in Vn:\n",
    "        ax[1].scatter(v[0], v[1], cmap=plt.cm.Set3);  \n",
    "    \n",
    "widgets.interact(update_plot, \n",
    "                 a1=FloatSlider_nice(min=-1, max=1, value=1.), \n",
    "                 a2=FloatSlider_nice(min=-1, max=1, value=0.), \n",
    "                 a3=FloatSlider_nice(min=-1, max=1, value=0),\n",
    "                 a4=FloatSlider_nice(min=-1, max=1, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ejes de la base trivial se escalan y rotan obteniendo un nuevo par de ejes (azul) \n",
    "\n",
    "La proyección de los vectores originales $\\vec v$ a los nuevos ejes es\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} x \\\\ y \\end{pmatrix} &=  A \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} \\\\\n",
    "A^{-1}\\begin{pmatrix} x \\\\ y \\end{pmatrix} &=   \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Por ejemplo si $A = \\begin{pmatrix} 0.5 & 0 \\\\ 0 & 1 \\end{pmatrix}$ tendríamos una nueva base donde el eje horizontal es \"más corto\" y la proyección de $(x, y)$ sería $(2x, y)$\n",
    "\n",
    "\n",
    "Consideremos una transformación en particular  $A = \\begin{pmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{pmatrix}$ y un vector cualquiera $v = \\rho \\begin{pmatrix} \\sin(\\theta) \\\\ \\cos(\\theta) \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 4), tight_layout=True)\n",
    "world_axis = np.array([[1, 0], [0, 1]])\n",
    "A = [[1, 0.5], [0.5, 1]]\n",
    "\n",
    "def update_plot(rho, theta):    \n",
    "    new_world_axis = np.dot(A, world_axis)\n",
    "    v = rho*np.array([np.cos(theta), np.sin(theta)])\n",
    "    ax.cla(); ax.set_aspect('equal')\n",
    "    ax.set_xlim([-1.2, 1.2]); ax.set_ylim([-1.2, 1.2]);  \n",
    "    ax.axis('off')\n",
    "\n",
    "    for j in range(2):\n",
    "        ax.arrow(0, 0, world_axis[0, j], world_axis[1, j], color='k', **arrow_args)\n",
    "        ax.arrow(0, 0, new_world_axis[0, j], new_world_axis[1, j], color='b', **arrow_args)\n",
    "    for v_,c  in zip([v, np.dot(A, v)], ['k', 'b']):\n",
    "        ax.scatter(v_[0], v_[1], color=c);\n",
    "        ax.arrow(0, 0, v_[0], v_[1], color=c, **arrow_args)\n",
    "    \n",
    "widgets.interact(update_plot, \n",
    "                 rho=FloatSlider_nice(min=0.1, max=2, value=1.),\n",
    "                 theta=FloatSlider_nice(min=-np.pi, max=np.pi, value=np.pi/4, step=1e-2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Existen algunos vectores que al ser cambiados de espacio mantienen su orientación original\n",
    "\n",
    "Pruebe por ejemplo $\\theta = \\pm \\pi/4 \\approx \\pm 0.7854$, es decir $v = \\frac{\\rho}{\\sqrt{2}} \\begin{pmatrix}  \\pm 1 \\\\ 1\\end{pmatrix}$\n",
    "\n",
    "> Los vectores que tienen ese ángulo solo son afectados en su escala\n",
    "\n",
    "Esos vectores se conocen como los **vectores propios** de $A$\n",
    "\n",
    "¿Cómo podemos encontrar los vectores propios para una matriz $A$ cualquiera?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema de los valores/vectores propios\n",
    "\n",
    "Sea una matriz cuadrada $A \\in \\mathbb{R}^{D\\times D}$\n",
    "\n",
    "El siguiente sistema de ecuaciones de $D$ ecuaciones\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "A \\vec v &= \\lambda I \\vec v \\\\\n",
    "(A - \\lambda I) \\vec v &= 0,\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "tiene como resultado $\\lambda$, los valores propios de $A$ y $\\vec v$ los vectores propios de $A$\n",
    "\n",
    "La solución no trivial de este problema ($\\vec v \\neq 0$) se obtiene si $(A - \\lambda I)$ es singular, luego su determinante\n",
    "\n",
    "$$\n",
    "|A - \\lambda I | = 0\n",
    "$$\n",
    "\n",
    "que resulta en un polinomio de grado $D$ cuyas raices son $\\{\\lambda_i\\}$, $i=1,2,\\ldots, D$\n",
    "\n",
    "Una vez determinado $\\lambda_i$ se pueden usar para despejar $\\vec v_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Para la matriz $A$ del ejemplo, si igualamos su determinante a cero tenemos\n",
    "\n",
    "$$\n",
    "(1 - \\lambda)^2 - 1/4 = 3/4 - 2\\lambda + \\lambda^2 = 0\n",
    "$$\n",
    "\n",
    "osea $\\lambda_1 = 1.5$ y $\\lambda_2 = 0.5$. Luego para el primer vector propio tenemos un sistema de ecuaciones\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "-0.5v_{11} +0.5v_{12} &= 0 \\\\\n",
    "0.5 v_{11} -0.5v_{12} &= 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "osea $v_{11} = v_{12}$ con esto podemos construir un vector normalizado genérico $v_1 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "De forma equivalente para $v_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "### Ahora con Python\n",
    "\n",
    "Podemos usar las funciones de [`scipy.linalg`](https://docs.scipy.org/doc/scipy/reference/linalg.html#eigenvalue-problems) `eig()` o `eigvals()` (y sus variantes) para resolver el sistema de ecuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "A = np.array([[1., 0.5], [0.5, 1]])\n",
    "evals, evecs = scipy.linalg.eig(A)\n",
    "display(evals, evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descomposicion en valores propios\n",
    "\n",
    "Existen [múltiples sistemas en física](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Applications) que [ocurren naturalmente](https://hubpages.com/education/What-the-Heck-are-Eigenvalues-and-Eigenvectors) como un problema de valores/vectores propios\n",
    "\n",
    "Sin embargo la aplicación más amplia para este elemento matemático es la **descomposición en vectores propios**\n",
    "\n",
    "> Descomponer: Expresar un elemento como una suma de partes de más simples\n",
    "\n",
    "La descomposición que veremos a continuación usa los **vectores propios** como \"las partes simples\"\n",
    "\n",
    "- ¿Cómo encontrar los vectores propios de una base de datos? ¿Qué intepretación tienen?\n",
    "- ¿Cómo descomponemos nuestros datos en función de los vectores propios?\n",
    "- ¿Qué ventaja tiene esta descomposición?\n",
    "\n",
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "Es un procedimiento estadístico que busca una **transformación ortogonal** para los datos que logre **maximizar su varianza**\n",
    "\n",
    "Para un conjunto de datos $\\{x_i\\}$ con $i=1,2,\\ldots, M$ y $x_i \\in \\mathbb{R}^D$\n",
    "\n",
    "Podemos escribirlo como una matriz $X \\in \\mathbb{R}^{D\\times M}$\n",
    "\n",
    "Podemos calcular su matriz de correlación como \n",
    "$$\n",
    "C = \\frac{1}{M} (X - \\bar X) ( X - \\bar X)^T\n",
    "$$\n",
    "\n",
    "donde $C \\in \\mathbb{R}^{D\\times D}$ y $\\bar X$ es la media del conjunto\n",
    "\n",
    "Llamemos $U$ a la matriz de proyección. El problema de PCA se puede escribir como\n",
    "\n",
    "$$\n",
    "\\max_U U C U^T \\text{ sujeto a } U^T U = I\n",
    "$$\n",
    "\n",
    "Si usamos multiplicadores de Lagrange para incluir la restricción y luego derivamos e igualamos a cero\n",
    "\n",
    "$$\n",
    "\\frac{d}{dU} U^T C U + \\Lambda(I- U^T U) = CU - \\Lambda U = 0\n",
    "$$\n",
    "\n",
    "donde $\\Lambda = \\lambda I$ y $\\lambda = (\\lambda_1, \\lambda_2, \\ldots, \\lambda_D)$\n",
    "\n",
    "> La transformación de PCA son los vectores propios de $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Iris\n",
    "\n",
    "Mostrar ejes proyectados\n",
    "\n",
    "Mostrar atributos del vp 1 y 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: *Eigen-faces* o Rostros principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "lfw_people = sklearn.datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "X = lfw_people['data'].T\n",
    "display(X.shape)\n",
    "fig, ax = plt.subplots(3, 7, figsize=(7, 4))\n",
    "for i, ax_ in enumerate(ax.ravel()):\n",
    "    ax_.axis('off')\n",
    "    ax_.imshow(X[:, i].reshape(50, 37), cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7, 2))\n",
    "ax.axis('off')\n",
    "ax.imshow(np.mean(X, axis=1).reshape(50, 37), cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X, axis=1, keepdims=True)\n",
    "X_center = X - X_mean\n",
    "C = np.dot(X_center, X_center.T)\n",
    "display(C.shape)\n",
    "L, U = scipy.linalg.eigh(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(L)[::-1] # Ordenar de L más grande a más pequeño\n",
    "L = L[idx]\n",
    "U = U[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 7, figsize=(7, 4.5), tight_layout=True)\n",
    "for i, ax_ in enumerate(ax.ravel()):\n",
    "    ax_.axis('off')\n",
    "    ax_.set_title(\"{0:0.1e}\".format(L[i]))\n",
    "    ax_.imshow(U[:, i].reshape(50, 37), cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula los coeficientes de la imagen 0\n",
    "P = np.dot(U.T, X_center[:, 0][:, None])\n",
    "# Esto regenera la imagen cero a partir de sus coeficientes\n",
    "Xhat = X_mean + np.dot(U, P)\n",
    "display(np.allclose(X[:, 0], Xhat[:, 0], rtol=1e-2))\n",
    "# ¿Cuantos coeficientes se necesitan para que X se parezca a Xhat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(5, 2))\n",
    "ax[0].axis('off'); ax[1].axis('off')\n",
    "ax[0].imshow(X[:, 0].reshape(50, 37), cmap=plt.cm.Greys_r)\n",
    "\n",
    "def update_plot(k):\n",
    "    Xhat = X_mean + np.dot(U[:, :k], P[:k])\n",
    "    ax[1].imshow(Xhat.reshape(50, 37), cmap=plt.cm.Greys_r)\n",
    "widgets.interact(update_plot, k=SelSlider_nice(options=[1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 1850]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "TODO\n",
    "\n",
    "https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
